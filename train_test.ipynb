{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "WORKS@!\n",
      "torch.Size([180])\n"
     ]
    }
   ],
   "source": [
    "%run model.ipynb\n",
    "%run Covid19AntigenDataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKS@!\n",
      "NEW!@@!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "dataset = Covid19AntigenDataset()\n",
    "\n",
    "train_size = int(0.9 * dataset.__len__())\n",
    "test_size = dataset.__len__() - train_size\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "learning_rate = 1e-4\n",
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "class_weights = [0.1,1]\n",
    "train_labels = [dataset.data[i][1] for i in train_set.indices]\n",
    "class_weights = [class_weights[label] for label in train_labels]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(class_weights), len(class_weights))\n",
    "\n",
    "# train_dataloader = DataLoader(train_set, batch_size=train_batch_size,sampler=sampler)\n",
    "train_dataloader = DataLoader(train_set, batch_size=train_batch_size,shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "# model = NeuralNetwork(216)\n",
    "model = NeuralNetwork(180)\n",
    "\n",
    "# weights = torch.Tensor([1,0.9])\n",
    "# loss_fn = BCELoss_class_weighted(weights)\n",
    "loss_fn = nn.BCELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    loop_loss = 0 \n",
    "    size = len(dataloader.dataset.indices)\n",
    "    correct = 0\n",
    "    pred_y = torch.Tensor([])\n",
    "    true_y = torch.Tensor([])\n",
    "        \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.float()\n",
    "        y = y.float()\n",
    "\n",
    "        pred = model(X)\n",
    "        pred_y = torch.cat((pred_y,(torch.flatten(pred) + 0.5).int()), 0)\n",
    "        true_y = torch.cat((true_y,torch.flatten(y)), 0)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    correct /= size\n",
    "    num_batches = len(dataloader)\n",
    "    loop_loss /= num_batches\n",
    "    print(f\"Train Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {loop_loss:>8f} \\n\")\n",
    "    return (true_y, pred_y, loop_loss)\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    pred_y = torch.Tensor([])\n",
    "    true_y = torch.Tensor([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.float()\n",
    "            y = y.float()\n",
    "            pred = model(X)\n",
    "            \n",
    "            pred_y = torch.cat((pred_y,(torch.flatten(pred) + 0.5).int()), 0)\n",
    "            true_y = torch.cat((true_y,torch.flatten(y)), 0)\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return (true_y, pred_y, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dort/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/Users/dort/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([30])) that is different to the input size (torch.Size([30, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/Users/dort/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([61])) that is different to the input size (torch.Size([61, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.298036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.188751 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.175293 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.157425 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.156463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.154336 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.149844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.153478 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.143951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.154381 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.138650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.153195 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.131726 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.152161 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.124629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.153978 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.115429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.155552 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.105678 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.158981 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.094451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.167708 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.083598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.172299 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.072238 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.176519 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.061754 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.187172 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.051969 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.194836 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.043195 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.211467 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.036027 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.221794 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.028397 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.228636 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.022827 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.247479 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.018486 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.256182 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.014513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.270594 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.011109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.292368 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.008977 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.307728 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.007374 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.316016 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.006166 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.340966 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.005633 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.363649 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.363286 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004488 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.394169 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004826 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.385478 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004585 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.388899 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.387831 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.398653 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004536 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.422145 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.003718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.413945 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.003852 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.424331 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.435043 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.445014 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.004338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.430992 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.002925 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.438404 \n",
      "\n",
      "tensor([0., 1.])\n",
      "Epoch 40\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "epochs = 40\n",
    "test_losses, test_accuracies, test_f1_scores, test_bas = [], [], [], []\n",
    "train_losses, train_accuracies, train_f1_scores, train_bas = [], [], [], []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_true_y, train_pred_y, train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_true_y, test_pred_y, test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "    test_accuracy = accuracy_score(test_true_y, test_pred_y, normalize=True)\n",
    "    train_accuracy = accuracy_score(train_true_y, train_pred_y, normalize=True)\n",
    "    \n",
    "    test_f1 = f1_score(test_true_y, test_pred_y)\n",
    "    train_f1 = f1_score(train_true_y, train_pred_y)\n",
    "    \n",
    "    print(torch.unique(test_pred_y))\n",
    "    \n",
    "    test_ba = balanced_accuracy_score(test_true_y, test_pred_y)\n",
    "    train_ba = balanced_accuracy_score(train_true_y, train_pred_y)\n",
    "    \n",
    "    test_losses += [test_loss]\n",
    "    test_accuracies += [test_accuracy]\n",
    "    test_f1_scores += [test_f1]\n",
    "    test_bas += [test_ba]\n",
    "    \n",
    "    train_losses += [train_loss]\n",
    "    train_accuracies += [train_accuracy]\n",
    "    train_f1_scores += [train_f1]\n",
    "    train_bas += [train_ba]\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "x = range(1, epochs +1)\n",
    "\n",
    "plt.plot(x, test_accuracies, label = \"test\")\n",
    "plt.plot(x, train_accuracies, label = \"train\")\n",
    "plt.ylabel('Accuracies')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('accuracies.png')\n",
    "\n",
    "plt.plot(x, test_f1_scores, label = \"test\")\n",
    "plt.plot(x, train_f1_scores, label = \"train\")\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('f1_score.png')\n",
    "\n",
    "plt.plot(x, test_bas, label = \"test\")\n",
    "plt.plot(x, train_bas, label = \"train\")\n",
    "plt.ylabel('Balanced Accuracies score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('balanced_accuracies.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(x, test_losses, label = \"test\")\n",
    "plt.plot(x, train_losses, label = \"train\")\n",
    "plt.ylabel('Losses')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
